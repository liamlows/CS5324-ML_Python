{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.0.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# graph visualization\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>ReviewBody</th>\n",
       "      <th>ReviewStar</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honest review of an edm music lover\\n</td>\n",
       "      <td>No doubt it has a great bass and to a great ex...</td>\n",
       "      <td>3</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unreliable earphones with high cost\\n</td>\n",
       "      <td>This  earphones are unreliable, i bought it be...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good and durable.\\n</td>\n",
       "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
       "      <td>4</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped working in just 14 days\\n</td>\n",
       "      <td>Its sound quality is adorable. overall it was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n</td>\n",
       "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>Good\\n</td>\n",
       "      <td>Good\\n</td>\n",
       "      <td>4</td>\n",
       "      <td>JBL T110BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>Amazing Product\\n</td>\n",
       "      <td>An amazing product but a bit costly.\\n</td>\n",
       "      <td>5</td>\n",
       "      <td>JBL T110BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>Not bad\\n</td>\n",
       "      <td>Sound\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>JBL T110BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14335</th>\n",
       "      <td>a good product\\n</td>\n",
       "      <td>the sound is good battery life is good but the...</td>\n",
       "      <td>5</td>\n",
       "      <td>JBL T110BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14336</th>\n",
       "      <td>Average headphones , n overrated name\\n</td>\n",
       "      <td>M writing this review after using for almost 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>JBL T110BT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14337 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ReviewTitle  \\\n",
       "0                 Honest review of an edm music lover\\n   \n",
       "1                 Unreliable earphones with high cost\\n   \n",
       "2                            Really good and durable.\\n   \n",
       "3                     stopped working in just 14 days\\n   \n",
       "4      Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n   \n",
       "...                                                 ...   \n",
       "14332                                            Good\\n   \n",
       "14333                                 Amazing Product\\n   \n",
       "14334                                         Not bad\\n   \n",
       "14335                                  a good product\\n   \n",
       "14336           Average headphones , n overrated name\\n   \n",
       "\n",
       "                                              ReviewBody  ReviewStar  \\\n",
       "0      No doubt it has a great bass and to a great ex...           3   \n",
       "1      This  earphones are unreliable, i bought it be...           1   \n",
       "2      i bought itfor 999,I purchased it second time,...           4   \n",
       "3      Its sound quality is adorable. overall it was ...           1   \n",
       "4      Its Awesome... Good sound quality & 8-9 hrs ba...           5   \n",
       "...                                                  ...         ...   \n",
       "14332                                             Good\\n           4   \n",
       "14333             An amazing product but a bit costly.\\n           5   \n",
       "14334                                            Sound\\n           1   \n",
       "14335  the sound is good battery life is good but the...           5   \n",
       "14336  M writing this review after using for almost 7...           1   \n",
       "\n",
       "                Product  \n",
       "0      boAt Rockerz 255  \n",
       "1      boAt Rockerz 255  \n",
       "2      boAt Rockerz 255  \n",
       "3      boAt Rockerz 255  \n",
       "4      boAt Rockerz 255  \n",
       "...                 ...  \n",
       "14332        JBL T110BT  \n",
       "14333        JBL T110BT  \n",
       "14334        JBL T110BT  \n",
       "14335        JBL T110BT  \n",
       "14336        JBL T110BT  \n",
       "\n",
       "[14337 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"reviews.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title = data[\"ReviewTitle\"]\n",
    "data_body = data[\"ReviewBody\"]\n",
    "y = data[\"ReviewStar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Honest review of an edm music lover\\n No doubt...\n",
       "1        Unreliable earphones with high cost\\n This  ea...\n",
       "2        Really good and durable.\\n i bought itfor 999,...\n",
       "3        stopped working in just 14 days\\n Its sound qu...\n",
       "4        Just Awesome Wireless Headphone under 1000...ðŸ˜‰...\n",
       "                               ...                        \n",
       "14332                                        Good\\n Good\\n\n",
       "14333    Amazing Product\\n An amazing product but a bit...\n",
       "14334                                    Not bad\\n Sound\\n\n",
       "14335    a good product\\n the sound is good battery lif...\n",
       "14336    Average headphones , n overrated name\\n M writ...\n",
       "Length: 14337, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = data[\"ReviewTitle\"].map(str) + \" \" + data[\"ReviewBody\"]\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12156 unique tokens. Distilled to 12156 top words.\n",
      "Shape of data tensor: (14337, 927)\n",
      "Shape of label tensor: (14337, 6)\n",
      "12156\n",
      "Wall time: 650 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_TOP_WORDS = None\n",
    "MAX_ART_LEN = 1000 # maximum and minimum number of words\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "sequences = tokenizer.texts_to_sequences(X_data)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
    "\n",
    "# X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "X = pad_sequences(sequences)\n",
    "\n",
    "\n",
    "y_ohe = keras.utils.to_categorical(y)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', y_ohe.shape)\n",
    "print(np.max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  149,   37,  133],\n",
       "       [   0,    0,    0, ..., 1634,    9,  301],\n",
       "       [   0,    0,    0, ...,  150,   31,   45],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   11,   70,    6],\n",
       "       [   0,    0,    0, ...,   18,    3,    9],\n",
       "       [   0,    0,    0, ...,   82,  298,  208]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11469, 927) (11469, 5)\n",
      "(2868, 927) (2868, 5)\n",
      "[1994.  751. 1203. 2551. 4970.]\n",
      "[ 499.  188.  300.  638. 1243.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split it into train / test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_ohe, test_size=0.2,\n",
    "                                                            stratify=y, \n",
    "                                                            random_state=42)\n",
    "\n",
    "# get rid of empty column at begginning\n",
    "y_train = y_train[:,1:]\n",
    "y_test = y_test[:,1:]\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "print(np.sum(y_train,axis=0))\n",
    "print(np.sum(y_test,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 927)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 927, 50)           607850    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 25)                1900      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 130       \n",
      "=================================================================\n",
      "Total params: 609,880\n",
      "Trainable params: 609,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "max_review_length = 927\n",
    "EMBED_SIZE = 50\n",
    "input_holder = Input(shape=(X_train.shape[1], ))\n",
    "input_embed = Embedding((np.max(X_train)+1), # input dimension (max int of OHE)\n",
    "                EMBED_SIZE, # output dimension size\n",
    "                input_length=max_review_length)(input_holder) # number of words in each sequence\n",
    "\n",
    "\n",
    "x = SimpleRNN(25,dropout=0.2, recurrent_dropout=0.2)(input_embed)\n",
    "x = Dense(NUM_CLASSES, activation='sigmoid')(x)\n",
    "rnn=Model(inputs=input_holder,outputs=x)\n",
    "rnn.compile(loss='binary_crossentropy', \n",
    "            optimizer='rmsprop', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liaml\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11469 samples, validate on 2868 samples\n",
      "Epoch 1/3\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.6318 - accuracy: 0.6415 - val_loss: 0.5064 - val_accuracy: 0.7955\n",
      "Epoch 2/3\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.5004 - accuracy: 0.7748 - val_loss: 0.4518 - val_accuracy: 0.7999\n",
      "Epoch 3/3\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.4688 - accuracy: 0.7905 - val_loss: 0.4456 - val_accuracy: 0.8059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d44f38edc8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11469 samples, validate on 2868 samples\n",
      "Epoch 1/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.4522 - accuracy: 0.8020 - val_loss: 0.4377 - val_accuracy: 0.8100\n",
      "Epoch 2/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.4370 - accuracy: 0.8102 - val_loss: 0.4282 - val_accuracy: 0.8156\n",
      "Epoch 3/15\n",
      "11469/11469 [==============================] - 135s 12ms/step - loss: 0.4277 - accuracy: 0.8157 - val_loss: 0.4199 - val_accuracy: 0.8204\n",
      "Epoch 4/15\n",
      "11469/11469 [==============================] - 137s 12ms/step - loss: 0.4193 - accuracy: 0.8186 - val_loss: 0.4128 - val_accuracy: 0.8225\n",
      "Epoch 5/15\n",
      "11469/11469 [==============================] - 135s 12ms/step - loss: 0.4088 - accuracy: 0.8234 - val_loss: 0.4067 - val_accuracy: 0.8268\n",
      "Epoch 6/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.4037 - accuracy: 0.8270 - val_loss: 0.4037 - val_accuracy: 0.8281\n",
      "Epoch 7/15\n",
      "11469/11469 [==============================] - 135s 12ms/step - loss: 0.3958 - accuracy: 0.8325 - val_loss: 0.3996 - val_accuracy: 0.8305\n",
      "Epoch 8/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.3893 - accuracy: 0.8348 - val_loss: 0.3976 - val_accuracy: 0.8305\n",
      "Epoch 9/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.3827 - accuracy: 0.8373 - val_loss: 0.3977 - val_accuracy: 0.8315\n",
      "Epoch 10/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.3775 - accuracy: 0.8402 - val_loss: 0.3934 - val_accuracy: 0.8338\n",
      "Epoch 11/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.3704 - accuracy: 0.8440 - val_loss: 0.3947 - val_accuracy: 0.8341\n",
      "Epoch 12/15\n",
      "11469/11469 [==============================] - 133s 12ms/step - loss: 0.3651 - accuracy: 0.8459 - val_loss: 0.3933 - val_accuracy: 0.8338\n",
      "Epoch 13/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.3631 - accuracy: 0.8453 - val_loss: 0.3928 - val_accuracy: 0.8346\n",
      "Epoch 14/15\n",
      "11469/11469 [==============================] - 135s 12ms/step - loss: 0.3604 - accuracy: 0.8481 - val_loss: 0.3978 - val_accuracy: 0.8328\n",
      "Epoch 15/15\n",
      "11469/11469 [==============================] - 136s 12ms/step - loss: 0.3563 - accuracy: 0.8488 - val_loss: 0.3951 - val_accuracy: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d44f8c3a48>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(X_train, y_train, \n",
    "        epochs=15, \n",
    "        batch_size=64, \n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=2)]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.save_weights('model_1_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
